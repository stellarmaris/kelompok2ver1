{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":96653,"databundleVersionId":11486515,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#from : https://www.kaggle.com/code/suyue715/tfidfvectorizer/notebook dengan beberapa modifikasi karena method berubah nama di versi baru ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:33:56.810950Z","iopub.execute_input":"2025-05-14T11:33:56.811393Z","iopub.status.idle":"2025-05-14T11:33:56.816518Z","shell.execute_reply.started":"2025-05-14T11:33:56.811367Z","shell.execute_reply":"2025-05-14T11:33:56.815610Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nfrom nltk.corpus import stopwords #buat pake tools stopwords punya nltk\nfrom nltk.tokenize import word_tokenize #buat pake tools tokenization punya nltk\nfrom nltk.stem import SnowballStemmer #buat pake tools stemmer (ngubah kata jadi kata dasar)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output #ini buat cek yang ada di direktori apa aja\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n#sama-sama tools NLP, yang pertama spacy yang kedua teks blob, nanti bisa bantu saat proses tokenisasi stemming dkk, \n#nanti pakai yang library EN karena bahasa penulis horornya pakai EN\nimport spacy #buat import spacy \nfrom textblob import TextBlob\n\n# Any results you write to the current directory are saved as output.\nfrom keras.preprocessing import sequence #import sequence buat model RNN/LSTM\nfrom tensorflow.keras.utils import to_categorical #impor fungsi mengubah label ke format one-hot encoding\nfrom keras.models import Sequential #buat model jaringan secara urut (satu-satu gitu)\nfrom keras.layers import Dense, Dropout, Activation, Embedding #buat jaringan saraf\nfrom keras.layers import LSTM #impor layer LSTM buat proses data secara sekuensial\n\nfrom sklearn.ensemble import RandomForestClassifier #buat klasifikasi berbasis banyak decision tree\nfrom sklearn.model_selection import train_test_split #buat pisahin data menjadi data train dan test\nfrom sklearn.metrics import confusion_matrix, classification_report #hitung confusion matriks sama buat report klasifikasi\nfrom sklearn.feature_extraction.text import CountVectorizer #ubah teks ke vektor berdasar jumlah kata\nfrom sklearn.decomposition import LatentDirichletAllocation #LDA untuk topik modelling\nfrom sklearn.feature_extraction.text import TfidfVectorizer #mengubah teks menjadi vektor berdasar TF-IDF\nfrom sklearn.decomposition import TruncatedSVD #buat reduksi dimensi setelah pake TF-IDF","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:33:56.817663Z","iopub.execute_input":"2025-05-14T11:33:56.817932Z","iopub.status.idle":"2025-05-14T11:34:27.582633Z","shell.execute_reply.started":"2025-05-14T11:33:56.817905Z","shell.execute_reply":"2025-05-14T11:34:27.581712Z"}},"outputs":[{"name":"stdout","text":"ir-2025-spooky-author-identification\n\n","output_type":"stream"},{"name":"stderr","text":"2025-05-14 11:34:11.983367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747222452.288981      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747222452.379929      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#Buat load datasets\ntrain = pd.read_csv('/kaggle/input/ir-2025-spooky-author-identification/train/train.csv')\ntest = pd.read_csv('/kaggle/input/ir-2025-spooky-author-identification/test/test.csv')\nsample = pd.read_csv('/kaggle/input/ir-2025-spooky-author-identification/sample_submission/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:27.583604Z","iopub.execute_input":"2025-05-14T11:34:27.584125Z","iopub.status.idle":"2025-05-14T11:34:27.796101Z","shell.execute_reply.started":"2025-05-14T11:34:27.584089Z","shell.execute_reply":"2025-05-14T11:34:27.795237Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"#Ini buat assign author ke kolom baru 'author_num'\n#0 -> 'EAP'\n#1 -> 'HPL'\n#2 -> 'MWS'\ntrain['author_num']=train['author'].apply({'EAP':0,  'HPL':1,'MWS':2}.get)\ntrain.head() #ini buat munculin datanya","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:27.798007Z","iopub.execute_input":"2025-05-14T11:34:27.798317Z","iopub.status.idle":"2025-05-14T11:34:27.834501Z","shell.execute_reply.started":"2025-05-14T11:34:27.798293Z","shell.execute_reply":"2025-05-14T11:34:27.833484Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        id                                               text author  \\\n0  id26305  This process, however, afforded me no means of...    EAP   \n1  id17569  It never once occurred to me that the fumbling...    HPL   \n2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n\n   author_num  \n0           0  \n1           1  \n2           0  \n3           2  \n4           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author</th>\n      <th>author_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id26305</td>\n      <td>This process, however, afforded me no means of...</td>\n      <td>EAP</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id17569</td>\n      <td>It never once occurred to me that the fumbling...</td>\n      <td>HPL</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id11008</td>\n      <td>In his left hand was a gold snuff box, from wh...</td>\n      <td>EAP</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27763</td>\n      <td>How lovely is spring As we looked from Windsor...</td>\n      <td>MWS</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id12958</td>\n      <td>Finding nothing else, not even gold, the Super...</td>\n      <td>HPL</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"#Ini buat assign feature sama targetnya\nX_text_train=train['text'].values\nX_text_test=test['text'].values\ny=train['author_num'].values\nnum_labels = len(np.unique(train['author_num']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:27.835353Z","iopub.execute_input":"2025-05-14T11:34:27.835676Z","iopub.status.idle":"2025-05-14T11:34:27.842404Z","shell.execute_reply.started":"2025-05-14T11:34:27.835646Z","shell.execute_reply":"2025-05-14T11:34:27.841477Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#Ini buat define stopword dan buat stemming , librarynya pakai bahasa EN\nstop_words = set(stopwords.words('english'))\nstop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\nstemmer = SnowballStemmer('english')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:27.843330Z","iopub.execute_input":"2025-05-14T11:34:27.843699Z","iopub.status.idle":"2025-05-14T11:34:27.868541Z","shell.execute_reply.started":"2025-05-14T11:34:27.843670Z","shell.execute_reply":"2025-05-14T11:34:27.867495Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# NLTK tokenize package","metadata":{}},{"cell_type":"code","source":"#Preprocess teks di train \nprocessed_train = []\nfor doc in X_text_train:\n    tokens = word_tokenize(doc)\n    filtered = [word for word in tokens if word not in stop_words]\n    stemmed = [stemmer.stem(word) for word in filtered]\n    processed_train.append(stemmed)\n#Preprocess teks di test\nprocessed_test = []\nfor doc in X_text_test:\n    tokens = word_tokenize(doc)\n    filtered = [word for word in tokens if word not in stop_words]\n    stemmed = [stemmer.stem(word) for word in filtered]\n    processed_test.append(stemmed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:27.869507Z","iopub.execute_input":"2025-05-14T11:34:27.869827Z","iopub.status.idle":"2025-05-14T11:34:36.404875Z","shell.execute_reply.started":"2025-05-14T11:34:27.869799Z","shell.execute_reply":"2025-05-14T11:34:36.403836Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#ini buat coba X_text_train / testing output. Output yang muncul itu indeks 1 dari X_text_train\nX_text_train[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.405922Z","iopub.execute_input":"2025-05-14T11:34:36.406207Z","iopub.status.idle":"2025-05-14T11:34:36.412026Z","shell.execute_reply.started":"2025-05-14T11:34:36.406182Z","shell.execute_reply":"2025-05-14T11:34:36.411080Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'It never once occurred to me that the fumbling might be a mere mistake.'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#ini buat coba tes processed_train / testing output. Output itu indeks 1 dari X_text_train yang udah di tokenisasi, udah di filter dari stopwords dan udah di stem (diubah ke bentuk dasar)\nprocessed_train[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.413398Z","iopub.execute_input":"2025-05-14T11:34:36.413736Z","iopub.status.idle":"2025-05-14T11:34:36.468743Z","shell.execute_reply.started":"2025-05-14T11:34:36.413709Z","shell.execute_reply":"2025-05-14T11:34:36.467787Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['it', 'never', 'occur', 'fumbl', 'might', 'mere', 'mistak']"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"#ini buat nambah kolom processed_train ke tabel test \ntrain['processed_train']=processed_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.472274Z","iopub.execute_input":"2025-05-14T11:34:36.472597Z","iopub.status.idle":"2025-05-14T11:34:36.492835Z","shell.execute_reply.started":"2025-05-14T11:34:36.472574Z","shell.execute_reply":"2025-05-14T11:34:36.491965Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#ini buat tes apakah kolom baru processed_train sudah masuk\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.493654Z","iopub.execute_input":"2025-05-14T11:34:36.493905Z","iopub.status.idle":"2025-05-14T11:34:36.518205Z","shell.execute_reply.started":"2025-05-14T11:34:36.493879Z","shell.execute_reply":"2025-05-14T11:34:36.517448Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"        id                                               text author  \\\n0  id26305  This process, however, afforded me no means of...    EAP   \n1  id17569  It never once occurred to me that the fumbling...    HPL   \n2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n\n   author_num                                    processed_train  \n0           0  [this, process, howev, afford, mean, ascertain...  \n1           1     [it, never, occur, fumbl, might, mere, mistak]  \n2           0  [in, left, hand, gold, snuff, box, caper, hill...  \n3           2  [how, love, spring, as, look, windsor, terrac,...  \n4           1  [find, noth, els, even, gold, superintend, aba...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author</th>\n      <th>author_num</th>\n      <th>processed_train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id26305</td>\n      <td>This process, however, afforded me no means of...</td>\n      <td>EAP</td>\n      <td>0</td>\n      <td>[this, process, howev, afford, mean, ascertain...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id17569</td>\n      <td>It never once occurred to me that the fumbling...</td>\n      <td>HPL</td>\n      <td>1</td>\n      <td>[it, never, occur, fumbl, might, mere, mistak]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id11008</td>\n      <td>In his left hand was a gold snuff box, from wh...</td>\n      <td>EAP</td>\n      <td>0</td>\n      <td>[in, left, hand, gold, snuff, box, caper, hill...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27763</td>\n      <td>How lovely is spring As we looked from Windsor...</td>\n      <td>MWS</td>\n      <td>2</td>\n      <td>[how, love, spring, as, look, windsor, terrac,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id12958</td>\n      <td>Finding nothing else, not even gold, the Super...</td>\n      <td>HPL</td>\n      <td>1</td>\n      <td>[find, noth, els, even, gold, superintend, aba...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#ini buat tau kolom apa aja yang udah ada di tabel train\ntrain.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.519132Z","iopub.execute_input":"2025-05-14T11:34:36.519448Z","iopub.status.idle":"2025-05-14T11:34:36.539609Z","shell.execute_reply.started":"2025-05-14T11:34:36.519398Z","shell.execute_reply":"2025-05-14T11:34:36.538645Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'text', 'author', 'author_num', 'processed_train'], dtype='object')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"#menggabungkan token hasil pre-processing menjadi kalimat utuh kemudian dijadikan satu di 'final_processed_text' di tabel train\n\nrow_lst = []\nfor lst in train.loc[:,'processed_train']:\n    text = ''\n    for word in lst:\n        text = text + ' ' + word\n    row_lst.append(text)\n\ntrain['final_processed_text'] = row_lst","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.540400Z","iopub.execute_input":"2025-05-14T11:34:36.540666Z","iopub.status.idle":"2025-05-14T11:34:36.634744Z","shell.execute_reply.started":"2025-05-14T11:34:36.540647Z","shell.execute_reply":"2025-05-14T11:34:36.633956Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#memasukkan kolom 'processed_test' di tabel test\ntest['processed_test']=processed_test\ntest.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.635625Z","iopub.execute_input":"2025-05-14T11:34:36.635932Z","iopub.status.idle":"2025-05-14T11:34:36.648109Z","shell.execute_reply.started":"2025-05-14T11:34:36.635910Z","shell.execute_reply":"2025-05-14T11:34:36.647084Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"        id                                               text  \\\n0  id02310  Still, as I urged our leaving Ireland with suc...   \n1  id24541  If a fire wanted fanning, it could readily be ...   \n2  id00134  And when they had broken down the frail door t...   \n3  id27757  While I was thinking how I should possibly man...   \n4  id04081  I am not sure to what limit his knowledge may ...   \n\n                                      processed_test  \n0  [still, i, urg, leav, ireland, inquietud, impa...  \n1  [if, fire, want, fan, could, readili, fan, new...  \n2  [and, broken, frail, door, found, two, clean, ...  \n3  [while, i, think, i, possibl, manag, without, ...  \n4            [i, sure, limit, knowledg, may, extend]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>processed_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id02310</td>\n      <td>Still, as I urged our leaving Ireland with suc...</td>\n      <td>[still, i, urg, leav, ireland, inquietud, impa...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id24541</td>\n      <td>If a fire wanted fanning, it could readily be ...</td>\n      <td>[if, fire, want, fan, could, readili, fan, new...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id00134</td>\n      <td>And when they had broken down the frail door t...</td>\n      <td>[and, broken, frail, door, found, two, clean, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27757</td>\n      <td>While I was thinking how I should possibly man...</td>\n      <td>[while, i, think, i, possibl, manag, without, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id04081</td>\n      <td>I am not sure to what limit his knowledge may ...</td>\n      <td>[i, sure, limit, knowledg, may, extend]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"#menggabungkan token hasil pre-processing menjadi kalimat utuh kemudian dijadikan satu di 'final_processed_text' di tabel test\n#memasukkan kolom 'final_processed_test' ke tabel test\nrow_lst = []\nfor lst in test.loc[:,'processed_test']:\n    text = ''\n    for word in lst:\n        text = text + ' ' + word\n    row_lst.append(text)\n\ntest['final_processed_test'] = row_lst\n\ntest.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.649031Z","iopub.execute_input":"2025-05-14T11:34:36.649311Z","iopub.status.idle":"2025-05-14T11:34:36.705883Z","shell.execute_reply.started":"2025-05-14T11:34:36.649292Z","shell.execute_reply":"2025-05-14T11:34:36.704991Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        id                                               text  \\\n0  id02310  Still, as I urged our leaving Ireland with suc...   \n1  id24541  If a fire wanted fanning, it could readily be ...   \n2  id00134  And when they had broken down the frail door t...   \n3  id27757  While I was thinking how I should possibly man...   \n4  id04081  I am not sure to what limit his knowledge may ...   \n\n                                      processed_test  \\\n0  [still, i, urg, leav, ireland, inquietud, impa...   \n1  [if, fire, want, fan, could, readili, fan, new...   \n2  [and, broken, frail, door, found, two, clean, ...   \n3  [while, i, think, i, possibl, manag, without, ...   \n4            [i, sure, limit, knowledg, may, extend]   \n\n                                final_processed_test  \n0   still i urg leav ireland inquietud impati fat...  \n1   if fire want fan could readili fan newspap go...  \n2   and broken frail door found two clean pick hu...  \n3   while i think i possibl manag without one act...  \n4                   i sure limit knowledg may extend  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>processed_test</th>\n      <th>final_processed_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id02310</td>\n      <td>Still, as I urged our leaving Ireland with suc...</td>\n      <td>[still, i, urg, leav, ireland, inquietud, impa...</td>\n      <td>still i urg leav ireland inquietud impati fat...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id24541</td>\n      <td>If a fire wanted fanning, it could readily be ...</td>\n      <td>[if, fire, want, fan, could, readili, fan, new...</td>\n      <td>if fire want fan could readili fan newspap go...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id00134</td>\n      <td>And when they had broken down the frail door t...</td>\n      <td>[and, broken, frail, door, found, two, clean, ...</td>\n      <td>and broken frail door found two clean pick hu...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27757</td>\n      <td>While I was thinking how I should possibly man...</td>\n      <td>[while, i, think, i, possibl, manag, without, ...</td>\n      <td>while i think i possibl manag without one act...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id04081</td>\n      <td>I am not sure to what limit his knowledge may ...</td>\n      <td>[i, sure, limit, knowledg, may, extend]</td>\n      <td>i sure limit knowledg may extend</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"#buat nge tes tabel train kolomnya udah ketambah semua atau belum\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.706837Z","iopub.execute_input":"2025-05-14T11:34:36.707073Z","iopub.status.idle":"2025-05-14T11:34:36.718050Z","shell.execute_reply.started":"2025-05-14T11:34:36.707054Z","shell.execute_reply":"2025-05-14T11:34:36.717378Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"        id                                               text author  \\\n0  id26305  This process, however, afforded me no means of...    EAP   \n1  id17569  It never once occurred to me that the fumbling...    HPL   \n2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n\n   author_num                                    processed_train  \\\n0           0  [this, process, howev, afford, mean, ascertain...   \n1           1     [it, never, occur, fumbl, might, mere, mistak]   \n2           0  [in, left, hand, gold, snuff, box, caper, hill...   \n3           2  [how, love, spring, as, look, windsor, terrac,...   \n4           1  [find, noth, els, even, gold, superintend, aba...   \n\n                                final_processed_text  \n0   this process howev afford mean ascertain dime...  \n1             it never occur fumbl might mere mistak  \n2   in left hand gold snuff box caper hill cut ma...  \n3   how love spring as look windsor terrac sixtee...  \n4   find noth els even gold superintend abandon a...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author</th>\n      <th>author_num</th>\n      <th>processed_train</th>\n      <th>final_processed_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id26305</td>\n      <td>This process, however, afforded me no means of...</td>\n      <td>EAP</td>\n      <td>0</td>\n      <td>[this, process, howev, afford, mean, ascertain...</td>\n      <td>this process howev afford mean ascertain dime...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id17569</td>\n      <td>It never once occurred to me that the fumbling...</td>\n      <td>HPL</td>\n      <td>1</td>\n      <td>[it, never, occur, fumbl, might, mere, mistak]</td>\n      <td>it never occur fumbl might mere mistak</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id11008</td>\n      <td>In his left hand was a gold snuff box, from wh...</td>\n      <td>EAP</td>\n      <td>0</td>\n      <td>[in, left, hand, gold, snuff, box, caper, hill...</td>\n      <td>in left hand gold snuff box caper hill cut ma...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27763</td>\n      <td>How lovely is spring As we looked from Windsor...</td>\n      <td>MWS</td>\n      <td>2</td>\n      <td>[how, love, spring, as, look, windsor, terrac,...</td>\n      <td>how love spring as look windsor terrac sixtee...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id12958</td>\n      <td>Finding nothing else, not even gold, the Super...</td>\n      <td>HPL</td>\n      <td>1</td>\n      <td>[find, noth, els, even, gold, superintend, aba...</td>\n      <td>find noth els even gold superintend abandon a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Named Entities","metadata":{}},{"cell_type":"code","source":"#ini buat install en_core_web_sm buat spacy\n!python -m spacy download en_core_web_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:34:36.718919Z","iopub.execute_input":"2025-05-14T11:34:36.719249Z","iopub.status.idle":"2025-05-14T11:35:13.899444Z","shell.execute_reply.started":"2025-05-14T11:34:36.719222Z","shell.execute_reply":"2025-05-14T11:35:13.898298Z"}},"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/socket.py\", line 974, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno -3] Temporary failure in name resolution\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 488, in _make_request\n    raise new_e\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 464, in _make_request\n    self._validate_conn(conn)\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 1093, in _validate_conn\n    conn.connect()\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 704, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 205, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x7ec9d39965d0>: Failed to resolve 'raw.githubusercontent.com' ([Errno -3] Temporary failure in name resolution)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7ec9d39965d0>: Failed to resolve 'raw.githubusercontent.com' ([Errno -3] Temporary failure in name resolution)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/usr/local/lib/python3.11/dist-packages/spacy/__main__.py\", line 4, in <module>\n    setup_cli()\n  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n    command(prog_name=COMMAND)\n  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n    return self.main(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 743, in main\n    return _main(\n           ^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 198, in _main\n    rv = self.invoke(ctx)\n         ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1697, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1443, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 788, in invoke\n    return __callback(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/typer/main.py\", line 698, in wrapper\n    return callback(**use_params)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/download.py\", line 44, in download_cli\n    download(model, direct, sdist, *ctx.args)\n  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/download.py\", line 85, in download\n    compatibility = get_compatibility()\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/download.py\", line 130, in get_compatibility\n    r = requests.get(about.__compatibility__)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 73, in get\n    return request(\"get\", url, params=params, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7ec9d39965d0>: Failed to resolve 'raw.githubusercontent.com' ([Errno -3] Temporary failure in name resolution)\"))\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"#ini buat nge load en_core_web_sm\nnlp = spacy.load('en_core_web_sm')\n\ncontent = []\nfor i in train['processed_train']:\n    content.append(i)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:35:13.900659Z","iopub.execute_input":"2025-05-14T11:35:13.901022Z","iopub.status.idle":"2025-05-14T11:35:14.820425Z","shell.execute_reply.started":"2025-05-14T11:35:13.900981Z","shell.execute_reply":"2025-05-14T11:35:14.819447Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Use LDA to identify topic","metadata":{}},{"cell_type":"code","source":"# menjalankan Topic Modeling dengan metode LDA (Latent Dirichlet Allocation) pada data teks menggunakan CountVectorizer dari Scikit-lear\nfrom sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD #ini buat import\ncv = CountVectorizer(stop_words='english') #ini buat ngatur stopwordnya dari EN\ncv.fit(train['text']) #ini buat train cv dari kolom teks\nX = cv.transform(train['text']) #ini buat ngubah dari teks ke matriks\nfeature_names = cv.get_feature_names_out() #ini mengambil daftar kata yang dipake cv\n\nlda = LatentDirichletAllocation(n_components=10) #ini buat lda dengan topiknya ada 10\nlda.fit(X) #melatih LDA\n\n#ini buat simpan result ke dataframe\nresults = pd.DataFrame(lda.components_,\n                      columns=feature_names)\n\n#ini intinya nge print\nfor topic in range(10):\n    print('Topic', topic)\n    word_list = results.T[topic].sort_values(ascending=False).index\n    print(' '.join(word_list[0:25]), '\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:35:14.821297Z","iopub.execute_input":"2025-05-14T11:35:14.821566Z","iopub.status.idle":"2025-05-14T11:35:47.302145Z","shell.execute_reply.started":"2025-05-14T11:35:14.821539Z","shell.execute_reply":"2025-05-14T11:35:47.301088Z"}},"outputs":[{"name":"stdout","text":"Topic 0\ntime man long door saw eyes great came light open house feet room say head did box thing floor place thought left length near wall \n\nTopic 1\nold man door adrian away time day eyes left night saw said room life hand long human idris city days like house raymond come turned \n\nTopic 2\ntime little think old said mind like thing did man saw took house day idea reason new home went believe matter world knew place night \n\nTopic 3\nlove said voice eyes death father heart words mother hand years know man heard life did shall sweet world thy like came length child hope \n\nTopic 4\nmr did old thing said quite soon time things heart really long room life great friend fear know having tell man death understand eyes case \n\nTopic 5\nsaid little great let place point like say way thought man face shall time life small general madame appeared mind marie degree make answer respect \n\nTopic 6\nshall did day life say things like let death come great saw long time heard human strange came friend house morning night thought light days \n\nTopic 7\nman night day know far felt like earth old life thing say mind city time strange long scene little sea did sky great years nature \n\nTopic 8\nraymond heart perdita life time little say moment eyes true soon soul mind long thought good love beloved father head nature great horror hands knew \n\nTopic 9\nthings like men did night seen old come came house water knew air time saw ye strange day man whateley got thought place life innsmouth \n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"#membagi dataset menjadi data pelatihan (train) dan data pengujian (test)\nX_train, X_test, y_train, y_test = train_test_split(train['final_processed_text'],\n                                                   train['author_num'],\n                                                   test_size=0.33,\n                                                   random_state=8675309)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:35:47.303130Z","iopub.execute_input":"2025-05-14T11:35:47.303363Z","iopub.status.idle":"2025-05-14T11:35:47.316851Z","shell.execute_reply.started":"2025-05-14T11:35:47.303344Z","shell.execute_reply":"2025-05-14T11:35:47.315899Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#ini dipake buat bangun dan eval model klasifikasi pake random forest\ncv = CountVectorizer(stop_words='english')\ncv.fit(X_train)\n\nX_train_cv = cv.transform(X_train)\nX_test_cv = cv.transform(X_test)\n\nrf = RandomForestClassifier()\nrf.fit(X_train_cv, y_train)\nprint(rf.score(X_test_cv, y_test))\npredictions = rf.predict(X_test_cv)\nprint(confusion_matrix(y_test, predictions))\nprint(classification_report(y_test, predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:35:47.317983Z","iopub.execute_input":"2025-05-14T11:35:47.318308Z","iopub.status.idle":"2025-05-14T11:36:12.245884Z","shell.execute_reply.started":"2025-05-14T11:35:47.318282Z","shell.execute_reply":"2025-05-14T11:36:12.245086Z"}},"outputs":[{"name":"stdout","text":"0.7079851439182916\n[[1950  278  434]\n [ 423 1156  247]\n [ 363  142 1469]]\n              precision    recall  f1-score   support\n\n           0       0.71      0.73      0.72      2662\n           1       0.73      0.63      0.68      1826\n           2       0.68      0.74      0.71      1974\n\n    accuracy                           0.71      6462\n   macro avg       0.71      0.70      0.70      6462\nweighted avg       0.71      0.71      0.71      6462\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# TfidfVectorizer() with English stop words","metadata":{}},{"cell_type":"code","source":"#ini intinya buat hitung tfidf\ntfidf = TfidfVectorizer(stop_words='english')\ntfidf.fit(X_train)\n\nX_train_tfidf = tfidf.transform(X_train)\nX_test_tfidf = tfidf.transform(X_test)\ntest_tfidf = tfidf.transform(test['final_processed_test'])\n\nrf = RandomForestClassifier()\nrf.fit(X_train_tfidf, y_train)\nprint(rf.score(X_test_tfidf, y_test))\npredictions = rf.predict(X_test_tfidf)\nprint(confusion_matrix(y_test, predictions))\nprint(classification_report(y_test, predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:36:12.246851Z","iopub.execute_input":"2025-05-14T11:36:12.247152Z","iopub.status.idle":"2025-05-14T11:36:35.862044Z","shell.execute_reply.started":"2025-05-14T11:36:12.247126Z","shell.execute_reply":"2025-05-14T11:36:35.861275Z"}},"outputs":[{"name":"stdout","text":"0.7140204271123491\n[[2034  277  351]\n [ 417 1226  183]\n [ 427  193 1354]]\n              precision    recall  f1-score   support\n\n           0       0.71      0.76      0.73      2662\n           1       0.72      0.67      0.70      1826\n           2       0.72      0.69      0.70      1974\n\n    accuracy                           0.71      6462\n   macro avg       0.72      0.71      0.71      6462\nweighted avg       0.71      0.71      0.71      6462\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"pred=rf.predict_proba(test_tfidf) #predict probabilitas\nprob=pd.DataFrame(pred,columns=['EAP','HPL','MWS']) #buat kolom\nsubmit1=pd.concat([test, prob], axis=1) #buat gabungin test sama prob\ndel submit1['text'] #hapus kolom text dari submit1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:36:35.862958Z","iopub.execute_input":"2025-05-14T11:36:35.863347Z","iopub.status.idle":"2025-05-14T11:36:36.941801Z","shell.execute_reply.started":"2025-05-14T11:36:35.863320Z","shell.execute_reply":"2025-05-14T11:36:36.940787Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"#hapus ['processed_test'] dari submit1\ndel submit1['processed_test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:36:36.942713Z","iopub.execute_input":"2025-05-14T11:36:36.943002Z","iopub.status.idle":"2025-05-14T11:36:36.947202Z","shell.execute_reply.started":"2025-05-14T11:36:36.942980Z","shell.execute_reply":"2025-05-14T11:36:36.946275Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"#hapus ['final_processed_test'] dari submit1\ndel submit1['final_processed_test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:36:36.948043Z","iopub.execute_input":"2025-05-14T11:36:36.948313Z","iopub.status.idle":"2025-05-14T11:36:36.972343Z","shell.execute_reply.started":"2025-05-14T11:36:36.948292Z","shell.execute_reply":"2025-05-14T11:36:36.971619Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"#hasil akhir\nsubmit1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:36:36.973531Z","iopub.execute_input":"2025-05-14T11:36:36.973901Z","iopub.status.idle":"2025-05-14T11:36:37.008113Z","shell.execute_reply.started":"2025-05-14T11:36:36.973879Z","shell.execute_reply":"2025-05-14T11:36:37.007068Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"           id       EAP       HPL       MWS\n0     id02310  0.140000  0.060000  0.800000\n1     id24541  0.743333  0.151667  0.105000\n2     id00134  0.290000  0.660000  0.050000\n3     id27757  0.456250  0.340625  0.203125\n4     id04081  0.827972  0.069528  0.102500\n...       ...       ...       ...       ...\n8387  id11749  0.712882  0.033628  0.253489\n8388  id10526  0.409947  0.123939  0.466114\n8389  id13477  0.700000  0.150000  0.150000\n8390  id13761  0.230000  0.180000  0.590000\n8391  id04282  0.800000  0.160000  0.040000\n\n[8392 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>EAP</th>\n      <th>HPL</th>\n      <th>MWS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id02310</td>\n      <td>0.140000</td>\n      <td>0.060000</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id24541</td>\n      <td>0.743333</td>\n      <td>0.151667</td>\n      <td>0.105000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id00134</td>\n      <td>0.290000</td>\n      <td>0.660000</td>\n      <td>0.050000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27757</td>\n      <td>0.456250</td>\n      <td>0.340625</td>\n      <td>0.203125</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id04081</td>\n      <td>0.827972</td>\n      <td>0.069528</td>\n      <td>0.102500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8387</th>\n      <td>id11749</td>\n      <td>0.712882</td>\n      <td>0.033628</td>\n      <td>0.253489</td>\n    </tr>\n    <tr>\n      <th>8388</th>\n      <td>id10526</td>\n      <td>0.409947</td>\n      <td>0.123939</td>\n      <td>0.466114</td>\n    </tr>\n    <tr>\n      <th>8389</th>\n      <td>id13477</td>\n      <td>0.700000</td>\n      <td>0.150000</td>\n      <td>0.150000</td>\n    </tr>\n    <tr>\n      <th>8390</th>\n      <td>id13761</td>\n      <td>0.230000</td>\n      <td>0.180000</td>\n      <td>0.590000</td>\n    </tr>\n    <tr>\n      <th>8391</th>\n      <td>id04282</td>\n      <td>0.800000</td>\n      <td>0.160000</td>\n      <td>0.040000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8392 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"#buat submission\nsubmit1.to_csv('./kelompok2ver1.csv', index=False, header=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T11:36:37.009206Z","iopub.execute_input":"2025-05-14T11:36:37.009542Z","iopub.status.idle":"2025-05-14T11:36:37.069220Z","shell.execute_reply.started":"2025-05-14T11:36:37.009513Z","shell.execute_reply":"2025-05-14T11:36:37.068490Z"}},"outputs":[],"execution_count":27}]}